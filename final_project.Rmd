---
title: 'Final Project: Dog Breeds'
author: "DÃ¡vid Winkler"
date: "2023-06-17"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(shiny)
```

# The dataset

In this project I will work with the tidytuesday 2022-02-01 dataset named Dog Breeds.The data is consisted from various characteristics of different dog breeds. You can check the descriptions of the traits in the trait_description dataset. You can also find the explanation of the values there. Generally the higher value represents the presence of the characteristics in the dog breed from 1 to 5. The coat types and coat lenghts are described with words. On default they are all set to character type variables.   



# Research question

In this assignment I will set up a hierarchical regression model to predict the barking nature of the dogs. My research will focus on the behavioural predictors of this ability. It seems logical for me that interpesonal traits could influence the barking level of dogs. I would like to investigate on which extend are the dog personality characteristics taking part in this behaviour.    

# Research method

After an explanatory data analysis I will make a model that will be reduced through feature engineering. I will make some explanatory data visualisation with the ggplot package. In the end I will compare the original and the reduced model based on AIC, adjusted R squared, and likelihood ratio test. From the research i will exclude the fur based qualities.  





```{r}
library(readxl) 
library(dplyr)
library(ggplot2)
library(ggrepel)
library(broom)
library(car) # For vif

breed_traits <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_traits.csv')
trait_description <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/trait_description.csv')
breed_rank_all <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_rank.csv')


```

## Exploratory data analysis
### Data diagnostics and correcting coding errors


Run an exploratory data analysis (EDA) to investigate the dataset. filter for most barking dogs with stranger openess and watchdog/protective nature. make shiny ggplot with their yearly ranks, 

```{r}
nrow(breed_traits) # We have 195 breeds.
# First we filter out the fur based qualities
breed_traits_filtered <- breed_traits %>%
  select(-c("Shedding Level", "Coat Grooming Frequency", "Drooling Level", "Coat Type", "Coat Length"))

# Now we set every data to numeric from character except Breed

breed_traits_filtered <- breed_traits_filtered %>%
  mutate(across(-Breed, as.numeric))

str(breed_traits_filtered) # Checking if we were successful

range(breed_traits_filtered$'Affectionate With Family') # Should be between 1-5, output indicates, there is some error in the data

filtered_breeds <- breed_traits_filtered %>%
  filter(`Affectionate With Family` < 1 | `Affectionate With Family` > 5) %>%  
  select(Breed)
range(breed_traits_filtered$'Affectionate With Family') # It is Plott Hounds

breed_traits_filtered <- breed_traits_filtered %>%
  filter(between(`Affectionate With Family`, 1, 5))

range(breed_traits_filtered$'Affectionate With Family') # Should be between 1-5
range(breed_traits_filtered$'Good With Young Children') # Should be between 1-5
range(breed_traits_filtered$'Good With Other Dogs') # Should be between 1-5
range(breed_traits_filtered$'Openness To Strangers') # Should be between 1-5
range(breed_traits_filtered$'Playfulness Level') # Should be between 1-5
range(breed_traits_filtered$'Watchdog/Protective Nature') # Should be between 1-5
range(breed_traits_filtered$'Adaptability Level') # Should be between 1-5
range(breed_traits_filtered$'Trainability Level') # Should be between 1-5
range(breed_traits_filtered$'Energy Level') # Should be between 1-5
range(breed_traits_filtered$'Barking Level') # Should be between 1-5
range(breed_traits_filtered$'Mental Stimulation Needs') # Should be between 1-5
range(breed_traits_filtered$'Affectionate With Family') # Should be between 1-5

# Outputs are indicating, that there are no more coding errors, or missing data
```
### Making an exploratory bar plot

In this bar plot you can observe the barking levels for every dog breed.   

```{r}
# Count the number of breeds for each Barking Level category
breed_counts <- breed_traits_filtered %>%
  count(`Barking Level`)

# Create a bar plot of breed counts by Barking Level
ggplot(breed_counts, aes(x = factor(`Barking Level`), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Barking Level", y = "Number of Breeds") +
  geom_text(aes(label = n, y = n), vjust = -0.5, color = "orange", size = 3) +
  scale_x_discrete(labels = c("1", "2", "3", "4", "5")) 
  
 
```
## Model building
### Build the more complex model

In order to test the more complex model for outliers and to test the assumptions first we build the model.

```{r}
complex_model <- lm(`Barking Level` ~ `Watchdog/Protective Nature` + `Openness To Strangers` + `Affectionate With Family` + `Good With Young Children` + `Good With Other Dogs` + `Playfulness Level` + `Adaptability Level` + `Trainability Level` + `Energy Level` + `Mental Stimulation Needs`, data = breed_traits_filtered)


```
### Finding most singificant predictors

In order to build the simpler model. We should run some model diagnostics to find the most relevant predictors.

```{r}
summary(complex_model) # As we can see Adaptability and Energy Level are the most significant predictors
```
### Build the simple model

Through some feature engineering it was confirmed, Adaptability Level and Energy Level are statistically significant.
```{r}
simple_model <- lm(`Barking Level` ~ `Adaptability Level` + `Energy Level`, data = breed_traits_filtered)

summary(simple_model)
```
## Exploratory plotting 
### Making a scatter plot

In this scatter plot you can observe the average barking levels for different dog breeds with their respective personalities according to their energy and adaptability levels. The number of observations are also highlighted.   

```{r}
breed_traits_summary <- breed_traits_filtered %>%
  group_by(`Adaptability Level`, `Energy Level`) %>%
  summarize(avg_Barking_Level = mean(`Barking Level`), num_breeds = n_distinct(Breed))

ggplot(breed_traits_summary, aes(x = `Adaptability Level`, y = `Energy Level`, color = avg_Barking_Level, label = num_breeds)) +
  geom_point() +
  geom_text_repel(size = 3, nudge_x = 0.1, nudge_y = 0.1) +
  labs(x = "Adaptability Level", y = "Energy Level", color = "Average Barking Level") +
  scale_color_gradient(low = "blue", high = "red")
```
### Interactive ggplot, representing the relationship between the dogs nature and the Barking Level

In this interactive plot you can set the Energy level and Adaptability level variables as you wish, to get the average Barking Level for those observations.Keep in mind, that there were unobserved combinations. (This part of the document interrupts the run all function in R)  
```{r}
# Define the UI
ui <- fluidPage(
  titlePanel("Barking Level Analysis"),
  sidebarLayout(
    sidebarPanel(
      sliderInput("energy", "Energy Level",
                  min = 1, max = 5, value = 3),
      sliderInput("adapt", "Adaptability Level:",
                  min = 1, max = 5, value = 3)
    ),
    mainPanel(
      plotOutput("barplot")
    )
  )
)

# Define the server logic
server <- function(input, output) {
  output$barplot <- renderPlot({
    filtered_data <- breed_traits_filtered %>%
      filter(`Energy Level` == input$energy,
             `Adaptability Level` == input$adapt) %>%
      group_by(`Energy Level`, `Adaptability Level`) %>%
      summarize(avg_Barking_Level = mean(`Barking Level`))

    ggplot(filtered_data, aes(x = factor(`Energy Level`), y = avg_Barking_Level, fill = factor(`Adaptability Level`))) +
      geom_bar(stat = "identity") +
      labs(x = "Energy Level", y = "Average Barking Level", fill = "Adaptability Level") +
      geom_text(aes(label = round(avg_Barking_Level, 2)), vjust = -0.5, size = 3) +
      scale_y_continuous(limits = c(0, 5))
  })
}

# Run the Shiny app
shinyApp(ui = ui, server = server)
 

 
```

### Model diagnostics


#### Checking the complex model for influential outliers

Check for outlier values in the complex model. Over 1 cook's distance the drog breed would be considered an outlier.

```{r}
# Set the default print options to show more columns
options(dplyr.width = Inf)


complex_model %>%
  augment() %>%
  select(`Watchdog/Protective Nature`,`Openness To Strangers`, `Affectionate With Family`, `Good With Young Children`, `Playfulness Level`, `Adaptability Level`, `Trainability Level`, `Energy Level`,`Good With Other Dogs`, `Mental Stimulation Needs`, cooks.dist = .cooksd) %>%
  arrange(desc(cooks.dist)) %>%
  head(10)

# As we can see every cook's distance value is well below zero, so we do not have outliers in the complex model
```
### Checking the simple model for influental outliers
```{r}
simple_model %>%
  augment() %>%
  select(`Adaptability Level`, `Energy Level`, cooks.dist = .cooksd) %>%
  arrange(desc(cooks.dist)) %>%
  head(10)

# As we can see every cook's distance value is well below zero, so we do not have outliers in the simple model
```
#### Checking assumptions
### Checking the complex model
Check the normality assumption.

```{r}
plot(complex_model, which = 2)
```

Check the linearity assumption.

```{r}
plot(complex_model, which = 1)
```

Check the homoscedasticty assumption (homogeneity of variance).

```{r}
plot(complex_model, which = 3) # It seems the variance of the Barking Level is middle heavy on the measuring scale
```

Checking the multicollinearity assumption. Over 5 VIF some variables are strongly correlated and we should reduce our model.

```{r}
# Calculate VIF
vif(complex_model) # Every one of our variables are well below zero, so we have not encountered high multicorrealianity in our model. Therefore we will not drop any of our predictor from the more complex model.
```

### Checking the simple model
Check the normality assumption.

```{r}
plot(simple_model, which = 2)
```

Check the linearity assumption.

```{r}
plot(simple_model, which = 1)
```

Check the homoscedasticty assumption (homogeneity of variance).

```{r}
plot(simple_model, which = 3) # It seems the variance of the Barking Level is middle heavy on the measuring scale
```

Checking the multicollinearity assumption. Over 5 VIF some variables are strongly correlated and we should reduce our model.

```{r}
# Calculate VIF
vif(simple_model) # Every one of our variables are well below zero, so we have not encountered high multicorrealianity in our model. Therefore we will not drop any of our predictor from the more complex model.
```

## Model comparison

Create the simple model and get the results of the model that needs to be reported based on the What to report section.

```{r}
summary(simple_model)

glance(simple_model) # Adjusted R squaired = 0.05314976	 AIC = 581.0652
```

Create the more complex model based on the results of the model diagnostics. Also, get the results that needs to be reported based on the What to report section.

```{r}
summary(complex_model)

glance(complex_model) # Adjusted R squaired = 0.02654137	 AIC = 594.1411
```

Compare the two models. 

The null model regression equation: Barking Level = 1.1094 + 0.2914 * Adaptability Level + 0.2456 * Energy Level


The complex model regression equation: Barking Level = 0.994692 + 0.031533 * Watchdog/Protective Nature + 0.038626 * Openness To Strangers - 0.079730 * Affectionate With Family + 0.054527 * Good With Young Children - 0.007455 * Good With Other Dogs + 0.136785 * Playfulness Level + 0.264693 * Adaptability Level - 0.102140 * Trainability Level + 0.203117 * Energy Level + 0.052016 * Mental Stimulation Needs

The coefficients are representing the estimated effect of each predictor variable on the response variable (Barking Level).

```{r}
anova(simple_model,complex_model) # F-statistic = 0.3474 p-value = 0.9461
```
## Discussion

### AIC and adjusted R-squared tests

#### Simple Model

Adjusted R-squared: 0.05314976

AIC: 581.0652

#### Complex Model

Adjusted R-squared: 0.02654137	 AIC = 594.1411 

AIC:594.1411  

#### AIC and adjusted R-squared findings

The Simple Model has a higher adjusted R-squared value (0.05314976) compared to the Complex Model (0.02654137). A higher adjusted R-squared indicates that a larger proportion of the variability in the dependent variable is accounted for by the predictors in the model. Therefore, the Simple Model explains more variability in the data than the Complex Model.

The Simple Model has a lower AIC value (581.0652) compared to the Complex Model (594.1411). A lower AIC indicates a better balance between model fit and complexity. Therefore, the Simple Model is preferred over the Complex Model in terms of the AIC criterion.

### Likelihood ratio test

F-statistic: 0.3474

p-value: 0.9461 

The likelihood ratio test statistic (F) is 0.3474 with a p-value of 0.9461. This suggests that the additional predictors in the complex model do not significantly improve the model fit compared to the simple model.

#### Final results

Considering both the adjusted R-squared and AIC, the simple model seems to be the better choice. It explains a slightly higher proportion of the variability in the data and has a lower AIC, suggesting a better fit while being less complex compared to the complex model.

